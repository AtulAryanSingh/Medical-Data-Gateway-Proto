{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63ad5188",
   "metadata": {},
   "source": [
    "# Medical Data Gateway — Demo Walkthrough\n",
    "\n",
    "This notebook walks through the full prototype pipeline:\n",
    "\n",
    "1. **DICOM Inspection** — load a file, explore metadata\n",
    "2. **The Privacy Problem** — show PHI tags, then anonymize\n",
    "3. **Medical Visualization** — windowing and HU conversion\n",
    "4. **Intensity Clustering** — K-Means on pixel values\n",
    "5. **Fleet Quality Control** — scanner anomaly detection\n",
    "6. **What Production Looks Like** — gaps and next steps\n",
    "\n",
    "> **Reminder:** This is a learning prototype. Nothing in this notebook constitutes medical advice or a compliance-ready solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd53703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pydicom\n",
    "from pydicom.dataset import FileDataset\n",
    "from pydicom.uid import ExplicitVRLittleEndian\n",
    "\n",
    "%matplotlib inline\n",
    "print(\"Imports OK\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68708b8",
   "metadata": {},
   "source": [
    "## 1. DICOM Inspection\n",
    "\n",
    "We create a synthetic DICOM dataset (since we have no real scan files in this repo) and inspect its metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a917c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_synthetic_dicom(patient_name=\"Doe^John\", patient_id=\"12345\", rows=64, cols=64):\n",
    "    \"\"\"Create a synthetic DICOM dataset for demonstration.\"\"\"\n",
    "    file_meta = pydicom.Dataset()\n",
    "    file_meta.MediaStorageSOPClassUID = pydicom.uid.UID(\"1.2.840.10008.5.1.4.1.1.2\")\n",
    "    file_meta.MediaStorageSOPInstanceUID = pydicom.uid.generate_uid()\n",
    "    file_meta.TransferSyntaxUID = ExplicitVRLittleEndian\n",
    "\n",
    "    ds = FileDataset(filename_or_obj=None, dataset={}, file_meta=file_meta, preamble=b\"\\0\" * 128)\n",
    "    ds.PatientName = patient_name\n",
    "    ds.PatientID = patient_id\n",
    "    ds.PatientBirthDate = \"19800101\"\n",
    "    ds.PatientSex = \"M\"\n",
    "    ds.StudyDate = \"20230601\"\n",
    "    ds.ContentDate = \"20230601\"\n",
    "    ds.StudyTime = \"120000\"\n",
    "    ds.ContentTime = \"120000\"\n",
    "    ds.AccessionNumber = \"ACC001\"\n",
    "    ds.StudyID = \"STUDY001\"\n",
    "    ds.InstitutionName = \"City General Hospital\"\n",
    "    ds.ReferringPhysicianName = \"Smith^Jane\"\n",
    "    ds.Modality = \"CT\"\n",
    "    ds.RescaleSlope = 1.0\n",
    "    ds.RescaleIntercept = -1024.0\n",
    "    ds.WindowCenter = 40.0\n",
    "    ds.WindowWidth = 400.0\n",
    "    ds.Rows = rows\n",
    "    ds.Columns = cols\n",
    "    ds.SamplesPerPixel = 1\n",
    "    ds.PhotometricInterpretation = \"MONOCHROME2\"\n",
    "    ds.PixelRepresentation = 0\n",
    "    ds.BitsAllocated = 16\n",
    "    ds.BitsStored = 16\n",
    "    ds.HighBit = 15\n",
    "\n",
    "    # Synthetic pixel data: simulate tissue density variation\n",
    "    rng = np.random.default_rng(42)\n",
    "    pixels = rng.integers(800, 1200, size=(rows, cols), dtype=np.uint16)\n",
    "    # Add a bright \"bone\" region\n",
    "    pixels[20:30, 20:40] = 1800\n",
    "    ds.PixelData = pixels.tobytes()\n",
    "    return ds\n",
    "\n",
    "ds = make_synthetic_dicom()\n",
    "print(\"DICOM Dataset loaded\")\n",
    "print(f\"  Patient Name   : {ds.PatientName}\")\n",
    "print(f\"  Patient ID     : {ds.PatientID}\")\n",
    "print(f\"  Institution    : {ds.InstitutionName}\")\n",
    "print(f\"  Study Date     : {ds.StudyDate}\")\n",
    "print(f\"  Modality       : {ds.Modality}\")\n",
    "print(f\"  Image size     : {ds.Rows} x {ds.Columns}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3d94f7",
   "metadata": {},
   "source": [
    "## 2. The Privacy Problem\n",
    "\n",
    "DICOM files embed patient identity in dozens of header tags.  If a scan file\n",
    "leaves the mobile unit unmodified, patient identity travels with it.\n",
    "\n",
    "Below we anonymize the dataset using `src.anonymizer` and verify the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4171c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.anonymizer import anonymize_dataset, TAGS_TO_REMOVE\n",
    "\n",
    "print(\"=== BEFORE ANONYMIZATION ===\")\n",
    "phi_tags = [\"PatientName\", \"PatientID\", \"PatientBirthDate\", \"InstitutionName\"]\n",
    "for tag in phi_tags:\n",
    "    print(f\"  {tag}: {getattr(ds, tag, '(not present)')}\")\n",
    "\n",
    "anonymize_dataset(ds, station_name=\"DEMO_UNIT_01\")\n",
    "\n",
    "print(\"\\n=== AFTER ANONYMIZATION ===\")\n",
    "for tag in phi_tags:\n",
    "    print(f\"  {tag}: {getattr(ds, tag, '(removed)')} \")\n",
    "\n",
    "print(f\"\\n  PatientIdentityRemoved : {ds.PatientIdentityRemoved}\")\n",
    "print(f\"  StationName            : {ds.StationName}\")\n",
    "print(f\"  DeidentificationMethod : {ds.DeidentificationMethod[:60]}...\")\n",
    "print(f\"\\nTotal PHI tags targeted for removal: {len(TAGS_TO_REMOVE)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2489c18",
   "metadata": {},
   "source": [
    "## 3. Medical Visualization — Windowing\n",
    "\n",
    "CT pixel values encode tissue density in Hounsfield Units (HU).  A *window*\n",
    "maps a clinically relevant HU range to the 0–255 display range.  The same\n",
    "slice looks completely different through a bone window vs a brain window.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0da922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.windowing import WINDOW_PRESETS, window_from_dataset\n",
    "\n",
    "# Re-create a fresh dataset (anonymize modified the previous one in-place)\n",
    "ds2 = make_synthetic_dicom()\n",
    "\n",
    "presets = list(WINDOW_PRESETS.keys())\n",
    "fig, axes = plt.subplots(1, len(presets), figsize=(4 * len(presets), 4))\n",
    "\n",
    "for ax, preset in zip(axes, presets):\n",
    "    windowed = window_from_dataset(ds2, preset=preset)\n",
    "    center, width = WINDOW_PRESETS[preset]\n",
    "    ax.imshow(windowed, cmap=\"gray\")\n",
    "    ax.set_title(f\"{preset.replace('_', ' ').title()}\\nC={center}, W={width}\", fontsize=10)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "fig.suptitle(\"Same CT Slice Through Different Clinical Windows\", fontsize=13)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "print(\"The bright square (simulated bone) appears very differently across windows.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39f2f8f",
   "metadata": {},
   "source": [
    "## 4. Intensity Clustering\n",
    "\n",
    "K-Means groups pixels by their windowed intensity value.  With k=3 clusters\n",
    "on a CT slice, the groups loosely correspond to air/soft-tissue/bone —\n",
    "but the algorithm has no knowledge of anatomy.\n",
    "\n",
    "**This is visualisation, not segmentation.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71742b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.clustering import cluster_scan\n",
    "\n",
    "ds3 = make_synthetic_dicom()\n",
    "windowed, cluster_map, silhouette = cluster_scan(ds3, n_clusters=3)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "ax1.imshow(windowed, cmap=\"gray\")\n",
    "ax1.set_title(\"Windowed Scan (soft_tissue preset)\", fontsize=11)\n",
    "ax1.axis(\"off\")\n",
    "\n",
    "ax2.imshow(cluster_map, cmap=\"plasma\")\n",
    "ax2.set_title(\n",
    "    f\"K-Means Intensity Clustering (k=3)\\nSilhouette score: {silhouette:.3f}\",\n",
    "    fontsize=11\n",
    ")\n",
    "ax2.axis(\"off\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "print(f\"Silhouette score: {silhouette:.3f}  (range: -1 to +1; higher = better separated clusters)\")\n",
    "print(\"Note: cluster labels are arbitrary integers — they don't map to named tissue types.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0fd69b",
   "metadata": {},
   "source": [
    "## 5. Fleet Quality Control\n",
    "\n",
    "In a real deployment, dozens of mobile scanners send files to a central\n",
    "server.  `src.scanner_qc` extracts simple statistics from each file and\n",
    "clusters the fleet to surface potential outliers.\n",
    "\n",
    "We simulate a small fleet of synthetic scans below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bd4a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile, os\n",
    "from src.scanner_qc import run_qc, ScanFeatures\n",
    "from src.visualization import plot_fleet_qc\n",
    "\n",
    "# Write synthetic DICOMs to a temp folder\n",
    "tmp_dir = tempfile.mkdtemp()\n",
    "\n",
    "def write_synthetic(path, mean_val, std_val, size=32):\n",
    "    rng = np.random.default_rng(hash(path) % (2**32))\n",
    "    pixels = rng.normal(mean_val, std_val, size=(size, size)).clip(0, 4095).astype(np.uint16)\n",
    "    file_meta = pydicom.Dataset()\n",
    "    file_meta.MediaStorageSOPClassUID = pydicom.uid.UID(\"1.2.840.10008.5.1.4.1.1.2\")\n",
    "    file_meta.MediaStorageSOPInstanceUID = pydicom.uid.generate_uid()\n",
    "    file_meta.TransferSyntaxUID = ExplicitVRLittleEndian\n",
    "    ds = FileDataset(path, {}, file_meta=file_meta, preamble=b\"\\0\" * 128)\n",
    "    ds.Rows, ds.Columns = size, size\n",
    "    ds.SamplesPerPixel = 1\n",
    "    ds.PhotometricInterpretation = \"MONOCHROME2\"\n",
    "    ds.PixelRepresentation = 0\n",
    "    ds.BitsAllocated = 16\n",
    "    ds.BitsStored = 16\n",
    "    ds.HighBit = 15\n",
    "    ds.PixelData = pixels.tobytes()\n",
    "    ds.save_as(path)\n",
    "\n",
    "# 6 \"normal\" scans + 2 \"anomalous\" scans\n",
    "for i in range(6):\n",
    "    write_synthetic(os.path.join(tmp_dir, f\"scan_{i:02d}.dcm\"), mean_val=1000, std_val=150)\n",
    "for i in range(6, 8):\n",
    "    write_synthetic(os.path.join(tmp_dir, f\"scan_{i:02d}.dcm\"), mean_val=400, std_val=50)\n",
    "\n",
    "records, matrix, labels, silhouette = run_qc(tmp_dir, n_clusters=2)\n",
    "\n",
    "print(f\"Files processed: {len(records)}\")\n",
    "print(f\"Silhouette score: {silhouette:.3f}\")\n",
    "print(\"\\nCluster assignments:\")\n",
    "for rec, label in zip(records, labels):\n",
    "    print(f\"  {rec.filename}  →  Group {label}  \"\n",
    "          f\"(density={rec.avg_density:.0f}, contrast={rec.contrast:.0f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd434ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_fleet_qc(records, labels, silhouette)\n",
    "plt.show()\n",
    "print(\"Scans in a different cluster may warrant investigation.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d3d109",
   "metadata": {},
   "source": [
    "## 6. What Production Looks Like\n",
    "\n",
    "This prototype deliberately keeps things simple.  A production system would need:\n",
    "\n",
    "| Gap | What's needed |\n",
    "|---|---|\n",
    "| UID remapping | Generate new unlinkable UIDs for every study/series/SOP |\n",
    "| Pixel scrubbing | OCR or ML model to detect burned-in text annotations |\n",
    "| Real upload | Authenticated HTTPS / S3 / DICOM-web with TLS |\n",
    "| Compliance audit | HIPAA/GDPR specialist review of the de-identification pipeline |\n",
    "| Containerisation | Docker image for consistent deployment on edge hardware |\n",
    "| Validated segmentation | Model trained on annotated ground-truth data, not K-Means |\n",
    "\n",
    "The `src/pipeline.py` module shows the exponential backoff pattern that\n",
    "any real upload should use — the mock just needs to be swapped for a real HTTP call.\n",
    "\n",
    "```python\n",
    "# Replace mock_upload with a real call, e.g.:\n",
    "import requests\n",
    "def real_upload(filename, url, auth_token):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        resp = requests.post(url, data=f, headers={\"Authorization\": f\"Bearer {auth_token}\"})\n",
    "    resp.raise_for_status()\n",
    "    return True\n",
    "```\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
